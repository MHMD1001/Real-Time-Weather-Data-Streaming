{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122f9ca2-49f3-410c-9cd3-554dff1954a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:12.992239Z",
     "iopub.status.busy": "2024-03-14T20:44:12.991722Z",
     "iopub.status.idle": "2024-03-14T20:44:13.513417Z",
     "shell.execute_reply": "2024-03-14T20:44:13.511665Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "import json\n",
    "import time\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd65767-13dd-4fb6-977a-1dbdcdaf00c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:13.518305Z",
     "iopub.status.busy": "2024-03-14T20:44:13.517872Z",
     "iopub.status.idle": "2024-03-14T20:44:24.843274Z",
     "shell.execute_reply": "2024-03-14T20:44:24.841218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize SparkSession \n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"spark://spark-master:7077\")\\\n",
    "    .appName(\"test_streaming\")\\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1\")\\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\")\\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fa6372-e911-4dbd-91bd-d29e887af497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:24.849664Z",
     "iopub.status.busy": "2024-03-14T20:44:24.848800Z",
     "iopub.status.idle": "2024-03-14T20:44:26.972966Z",
     "shell.execute_reply": "2024-03-14T20:44:26.971436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read streaming data from Kafka\n",
    "kafka_df = spark.readStream\\\n",
    "        .format(\"kafka\")\\\n",
    "        .option(\"kafka.bootstrap.servers\",\"broker:29092\")\\\n",
    "        .option(\"subscribe\",\"weather_data\")\\\n",
    "        .option(\"startingOffsets\",\"earliest\")\\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a7da45b-2e2e-4193-a694-3f04742cf448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:26.978303Z",
     "iopub.status.busy": "2024-03-14T20:44:26.977549Z",
     "iopub.status.idle": "2024-03-14T20:44:26.986181Z",
     "shell.execute_reply": "2024-03-14T20:44:26.985111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to parse streaming data\n",
    "def parsing_streaming_data(data):\n",
    "    # Defining a schema\n",
    "    schema = StructType([\n",
    "    StructField(\"city_id\", StringType()),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"weather_condition\", StringType(), True),\n",
    "    StructField(\"weather_description\", StringType(), True),\n",
    "    StructField(\"temperature\", DecimalType(5,2), True),\n",
    "    StructField(\"min_temp\", DecimalType(5,2), True),\n",
    "    StructField(\"max_temp\", DecimalType(5,2), True),\n",
    "    StructField(\"pressure\", IntegerType(), True),\n",
    "    StructField(\"humidity\", DecimalType(4,2), True),\n",
    "    StructField(\"wind_speed\", DecimalType(4,2), True),\n",
    "    StructField(\"visibility\", DecimalType(6,1), True),\n",
    "    StructField(\"creation_time\", TimestampType())\n",
    "])\n",
    "    # Convert the value column to json string and store it in a new dataframe\n",
    "    stream_data =data.selectExpr(\"Cast (value As string)\")\n",
    "    # Parse json and apply schema\n",
    "    parsed_data = stream_data.select(fn.from_json(fn.col(\"value\"), schema).alias(\"data\"))\n",
    "    # Return the parsed data\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6412eb75-ec40-41f0-9a10-c488e14c162b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:26.990610Z",
     "iopub.status.busy": "2024-03-14T20:44:26.989814Z",
     "iopub.status.idle": "2024-03-14T20:44:26.995457Z",
     "shell.execute_reply": "2024-03-14T20:44:26.994401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to select the relevant fields from the streamed data\n",
    "def select_columns(data): \n",
    "    # Create a dataframe with the relevant column\n",
    "    selected_data = data.select('data.*')\n",
    "    # Return a df with the relevant fields\n",
    "    return selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539b7fdf-cf4d-447b-baf4-c18e65d438d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:26.999415Z",
     "iopub.status.busy": "2024-03-14T20:44:26.998825Z",
     "iopub.status.idle": "2024-03-14T20:44:27.005749Z",
     "shell.execute_reply": "2024-03-14T20:44:27.004643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define to make some transformations\n",
    "def transform_measurement_units(data):\n",
    "    # Create a temp view from the data to do trnsformations with spark sql\n",
    "    data.createOrReplaceTempView(\"streaming_data\")\n",
    "    # Making the necessary Transformations\n",
    "    transformed_data = spark.sql(\"\"\"SELECT \n",
    "                                        city_id,\n",
    "                                        city,\n",
    "                                        weather_condition,\n",
    "                                        weather_description,\n",
    "                                        Round(temperature-272.15,2) AS temperature,\n",
    "                                        Round(min_temp-272.15,2) AS min_temp,\n",
    "                                        Round(max_temp-272.15,2) AS max_temp,\n",
    "                                        pressure,\n",
    "                                        humidity,\n",
    "                                        ROUND(wind_speed*3.6,2) AS wind_speed,\n",
    "                                        visibility,\n",
    "                                        creation_time,\n",
    "                                        TO_DATE (creation_time,\"yyy-MM-dd\") AS creation_date\n",
    "                                From streaming_data\"\"\")\n",
    "    #Return the transformed df\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78170b8b-e222-44e3-8f43-74f171c4bacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:27.010197Z",
     "iopub.status.busy": "2024-03-14T20:44:27.009349Z",
     "iopub.status.idle": "2024-03-14T20:44:27.368029Z",
     "shell.execute_reply": "2024-03-14T20:44:27.366800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parsing the streamed data\n",
    "parsed_df = parsing_streaming_data(kafka_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b0c9e-65ce-4c35-9a08-7cf69b9bc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the relevant columns from the streamed data\n",
    "weather_df = select_columns(parsed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c9d7eee-15b3-4da5-8a16-44fe76938e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:27.443600Z",
     "iopub.status.busy": "2024-03-14T20:44:27.443100Z",
     "iopub.status.idle": "2024-03-14T20:44:28.211404Z",
     "shell.execute_reply": "2024-03-14T20:44:28.209752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make transformations to the data\n",
    "transformed_df = transform_measurement_units(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea23445-16d2-4a0a-a48f-3560ed980126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:28.230516Z",
     "iopub.status.busy": "2024-03-14T20:44:28.229711Z",
     "iopub.status.idle": "2024-03-14T20:44:28.236367Z",
     "shell.execute_reply": "2024-03-14T20:44:28.234579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to create Hive table using spark sql\n",
    "def creating_hive_taple(data):    \n",
    "    hive_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS default.weather_data (\n",
    "        city_id STRING,\n",
    "        city STRING,\n",
    "        weather_condition STRING,\n",
    "        weather_description STRING,\n",
    "        temperature DOUBLE,\n",
    "        min_temp DOUBLE,\n",
    "        max_temp DOUBLE,\n",
    "        pressure INTEGER,\n",
    "        humidity DOUBLE,\n",
    "        wind_speed DOUBLE,\n",
    "        visibility DOUBLE,\n",
    "        creation_time TIMESTAMP,\n",
    "        creation_date DATE\n",
    "    )\n",
    "    USING Parquet\n",
    "    PARTITIONED BY (creation_date)\n",
    "    LOCATION 'hdfs://namenode:9000/data/streaming/weather_data/hive_table'\n",
    "    \"\"\"    \n",
    "    # Creating hive table\n",
    "    spark.sql(hive_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93ee10d5-ab09-4e30-846b-51153c05d7dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:28.241554Z",
     "iopub.status.busy": "2024-03-14T20:44:28.240596Z",
     "iopub.status.idle": "2024-03-14T20:44:28.248101Z",
     "shell.execute_reply": "2024-03-14T20:44:28.246699Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to start Hive streaming query\n",
    "def start_hive_streaming_query(data):\n",
    "    query = data \\\n",
    "    .writeStream \\\n",
    "    .foreachBatch(lambda batch_df, batch_id: batch_df.write.mode(\"append\").insertInto(\"weather_data\")) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8099e7b6-b04a-460a-9bc5-aa3e26db9e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:28.252738Z",
     "iopub.status.busy": "2024-03-14T20:44:28.252151Z",
     "iopub.status.idle": "2024-03-14T20:44:29.624430Z",
     "shell.execute_reply": "2024-03-14T20:44:29.622877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Hive table\n",
    "creating_hive_taple(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "127ced13-4b25-456f-b715-3e3f6353df52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:29.629991Z",
     "iopub.status.busy": "2024-03-14T20:44:29.629176Z",
     "iopub.status.idle": "2024-03-14T20:44:30.139148Z",
     "shell.execute_reply": "2024-03-14T20:44:30.137623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start Hive streaming query\n",
    "query = start_hive_streaming_query(transformed_df)\n",
    "query.awaitTermination() # Wait for query termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f84ced3-fb15-473e-92bd-d0bbf196cf5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T20:44:30.145097Z",
     "iopub.status.busy": "2024-03-14T20:44:30.143836Z",
     "iopub.status.idle": "2024-03-14T20:44:30.265982Z",
     "shell.execute_reply": "2024-03-14T20:44:30.264363Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stop SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
